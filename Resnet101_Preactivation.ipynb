{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tester PreAct.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12fd2d9ea2da4b29b00e1a5658e6dfec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f88a9d2b1c64d9ab8ab774fa921bcfb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f47ee38fe8a4e63a7ee7e7773e002a5",
              "IPY_MODEL_8bcbf72243754a73adcbf802f7cec86e"
            ]
          }
        },
        "8f88a9d2b1c64d9ab8ab774fa921bcfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f47ee38fe8a4e63a7ee7e7773e002a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6bc0cb2d4bb4865b56f4a566d92b4bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c728e97c8119456a9c1ff9b1bcd417e4"
          }
        },
        "8bcbf72243754a73adcbf802f7cec86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e555cc609cf44fa286641256332de9da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:09&lt;00:00, 17341388.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b2fcdce2bb64d8898302ea25a5e3560"
          }
        },
        "a6bc0cb2d4bb4865b56f4a566d92b4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c728e97c8119456a9c1ff9b1bcd417e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e555cc609cf44fa286641256332de9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b2fcdce2bb64d8898302ea25a5e3560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "unhI5N2KZozz",
        "colab_type": "code",
        "outputId": "2a3a623f-6abe-42fa-d321-75562dabbddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "12fd2d9ea2da4b29b00e1a5658e6dfec",
            "8f88a9d2b1c64d9ab8ab774fa921bcfb",
            "3f47ee38fe8a4e63a7ee7e7773e002a5",
            "8bcbf72243754a73adcbf802f7cec86e",
            "a6bc0cb2d4bb4865b56f4a566d92b4bc",
            "c728e97c8119456a9c1ff9b1bcd417e4",
            "e555cc609cf44fa286641256332de9da",
            "4b2fcdce2bb64d8898302ea25a5e3560"
          ]
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "\n",
        "class PreActBlock(nn.Module):\n",
        "    '''Pre-activation version of the BasicBlock.'''\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(PreActBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "\n",
        "class PreActBottleneck(nn.Module):\n",
        "    '''Pre-activation version of the original Bottleneck module.'''\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(PreActBottleneck, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out = self.conv3(F.relu(self.bn3(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "\n",
        "class PreActResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(PreActResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(10, resample=False, expand=False, center=None, fill=0),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([                                 \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "\n",
        "net = PreActResNet(PreActBlock, [3,4,6,3])\n",
        "# net = PreActResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    print(f'Training accuracy for epoch {epoch}:{100*(correct/total)}')\n",
        "\n",
        "        \n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    print(f'Testing accuracy for epoch {epoch}:{100*(correct/total)}')\n",
        "\n",
        "            \n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "print(best_acc)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12fd2d9ea2da4b29b00e1a5658e6dfec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "\n",
            "\n",
            "Epoch: 0\n",
            "Training accuracy for epoch 0:21.146\n",
            "Testing accuracy for epoch 0:27.6\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            "Training accuracy for epoch 1:35.583999999999996\n",
            "Testing accuracy for epoch 1:42.17\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            "Training accuracy for epoch 2:44.254\n",
            "Testing accuracy for epoch 2:46.04\n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            "Training accuracy for epoch 3:50.38\n",
            "Testing accuracy for epoch 3:51.300000000000004\n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            "Training accuracy for epoch 4:54.76\n",
            "Testing accuracy for epoch 4:56.510000000000005\n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            "Training accuracy for epoch 5:58.742000000000004\n",
            "Testing accuracy for epoch 5:54.790000000000006\n",
            "\n",
            "Epoch: 6\n",
            "Training accuracy for epoch 6:62.452\n",
            "Testing accuracy for epoch 6:62.06\n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            "Training accuracy for epoch 7:65.24600000000001\n",
            "Testing accuracy for epoch 7:63.580000000000005\n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            "Training accuracy for epoch 8:67.196\n",
            "Testing accuracy for epoch 8:69.04\n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            "Training accuracy for epoch 9:69.794\n",
            "Testing accuracy for epoch 9:67.62\n",
            "\n",
            "Epoch: 10\n",
            "Training accuracy for epoch 10:72.11\n",
            "Testing accuracy for epoch 10:71.7\n",
            "Saving..\n",
            "\n",
            "Epoch: 11\n",
            "Training accuracy for epoch 11:73.71\n",
            "Testing accuracy for epoch 11:70.11\n",
            "\n",
            "Epoch: 12\n",
            "Training accuracy for epoch 12:75.508\n",
            "Testing accuracy for epoch 12:76.9\n",
            "Saving..\n",
            "\n",
            "Epoch: 13\n",
            "Training accuracy for epoch 13:76.74600000000001\n",
            "Testing accuracy for epoch 13:75.66000000000001\n",
            "\n",
            "Epoch: 14\n",
            "Training accuracy for epoch 14:77.16199999999999\n",
            "Testing accuracy for epoch 14:77.75999999999999\n",
            "Saving..\n",
            "\n",
            "Epoch: 15\n",
            "Training accuracy for epoch 15:78.378\n",
            "Testing accuracy for epoch 15:78.03999999999999\n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            "Training accuracy for epoch 16:80.196\n",
            "Testing accuracy for epoch 16:80.11\n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            "Training accuracy for epoch 17:81.294\n",
            "Testing accuracy for epoch 17:79.97\n",
            "\n",
            "Epoch: 18\n",
            "Training accuracy for epoch 18:81.89\n",
            "Testing accuracy for epoch 18:80.88\n",
            "Saving..\n",
            "\n",
            "Epoch: 19\n",
            "Training accuracy for epoch 19:82.804\n",
            "Testing accuracy for epoch 19:80.71000000000001\n",
            "\n",
            "Epoch: 20\n",
            "Training accuracy for epoch 20:82.526\n",
            "Testing accuracy for epoch 20:79.66\n",
            "\n",
            "Epoch: 21\n",
            "Training accuracy for epoch 21:84.00999999999999\n",
            "Testing accuracy for epoch 21:83.05\n",
            "Saving..\n",
            "\n",
            "Epoch: 22\n",
            "Training accuracy for epoch 22:84.804\n",
            "Testing accuracy for epoch 22:80.80000000000001\n",
            "\n",
            "Epoch: 23\n",
            "Training accuracy for epoch 23:84.85000000000001\n",
            "Testing accuracy for epoch 23:85.39999999999999\n",
            "Saving..\n",
            "\n",
            "Epoch: 24\n",
            "Training accuracy for epoch 24:85.426\n",
            "Testing accuracy for epoch 24:83.41\n",
            "\n",
            "Epoch: 25\n",
            "Training accuracy for epoch 25:86.31\n",
            "Testing accuracy for epoch 25:84.13000000000001\n",
            "\n",
            "Epoch: 26\n",
            "Training accuracy for epoch 26:86.568\n",
            "Testing accuracy for epoch 26:84.83000000000001\n",
            "\n",
            "Epoch: 27\n",
            "Training accuracy for epoch 27:86.992\n",
            "Testing accuracy for epoch 27:84.91\n",
            "\n",
            "Epoch: 28\n",
            "Training accuracy for epoch 28:87.476\n",
            "Testing accuracy for epoch 28:85.41\n",
            "Saving..\n",
            "\n",
            "Epoch: 29\n",
            "Training accuracy for epoch 29:88.09\n",
            "Testing accuracy for epoch 29:84.72\n",
            "\n",
            "Epoch: 30\n",
            "Training accuracy for epoch 30:88.32600000000001\n",
            "Testing accuracy for epoch 30:87.77000000000001\n",
            "Saving..\n",
            "\n",
            "Epoch: 31\n",
            "Training accuracy for epoch 31:88.198\n",
            "Testing accuracy for epoch 31:87.14\n",
            "\n",
            "Epoch: 32\n",
            "Training accuracy for epoch 32:88.994\n",
            "Testing accuracy for epoch 32:87.58\n",
            "\n",
            "Epoch: 33\n",
            "Training accuracy for epoch 33:89.33\n",
            "Testing accuracy for epoch 33:88.14999999999999\n",
            "Saving..\n",
            "\n",
            "Epoch: 34\n",
            "Training accuracy for epoch 34:89.492\n",
            "Testing accuracy for epoch 34:87.0\n",
            "\n",
            "Epoch: 35\n",
            "Training accuracy for epoch 35:89.946\n",
            "Testing accuracy for epoch 35:86.78\n",
            "\n",
            "Epoch: 36\n",
            "Training accuracy for epoch 36:89.942\n",
            "Testing accuracy for epoch 36:88.02\n",
            "\n",
            "Epoch: 37\n",
            "Training accuracy for epoch 37:89.474\n",
            "Testing accuracy for epoch 37:87.68\n",
            "\n",
            "Epoch: 38\n",
            "Training accuracy for epoch 38:90.602\n",
            "Testing accuracy for epoch 38:86.64\n",
            "\n",
            "Epoch: 39\n",
            "Training accuracy for epoch 39:91.16\n",
            "Testing accuracy for epoch 39:88.42999999999999\n",
            "Saving..\n",
            "\n",
            "Epoch: 40\n",
            "Training accuracy for epoch 40:91.266\n",
            "Testing accuracy for epoch 40:88.29\n",
            "\n",
            "Epoch: 41\n",
            "Training accuracy for epoch 41:91.13\n",
            "Testing accuracy for epoch 41:88.11\n",
            "\n",
            "Epoch: 42\n",
            "Training accuracy for epoch 42:91.62599999999999\n",
            "Testing accuracy for epoch 42:89.77000000000001\n",
            "Saving..\n",
            "\n",
            "Epoch: 43\n",
            "Training accuracy for epoch 43:91.64999999999999\n",
            "Testing accuracy for epoch 43:89.03999999999999\n",
            "\n",
            "Epoch: 44\n",
            "Training accuracy for epoch 44:92.082\n",
            "Testing accuracy for epoch 44:88.96\n",
            "\n",
            "Epoch: 45\n",
            "Training accuracy for epoch 45:92.104\n",
            "Testing accuracy for epoch 45:89.5\n",
            "\n",
            "Epoch: 46\n",
            "Training accuracy for epoch 46:92.54400000000001\n",
            "Testing accuracy for epoch 46:89.52\n",
            "\n",
            "Epoch: 47\n",
            "Training accuracy for epoch 47:92.84599999999999\n",
            "Testing accuracy for epoch 47:89.07000000000001\n",
            "\n",
            "Epoch: 48\n",
            "Training accuracy for epoch 48:87.17\n",
            "Testing accuracy for epoch 48:83.26\n",
            "\n",
            "Epoch: 49\n",
            "Training accuracy for epoch 49:89.52799999999999\n",
            "Testing accuracy for epoch 49:89.1\n",
            "\n",
            "Epoch: 50\n",
            "Training accuracy for epoch 50:91.282\n",
            "Testing accuracy for epoch 50:89.67\n",
            "\n",
            "Epoch: 51\n",
            "Training accuracy for epoch 51:92.794\n",
            "Testing accuracy for epoch 51:90.33\n",
            "Saving..\n",
            "\n",
            "Epoch: 52\n",
            "Training accuracy for epoch 52:93.484\n",
            "Testing accuracy for epoch 52:89.94\n",
            "\n",
            "Epoch: 53\n",
            "Training accuracy for epoch 53:93.252\n",
            "Testing accuracy for epoch 53:90.62\n",
            "Saving..\n",
            "\n",
            "Epoch: 54\n",
            "Training accuracy for epoch 54:93.718\n",
            "Testing accuracy for epoch 54:90.14999999999999\n",
            "\n",
            "Epoch: 55\n",
            "Training accuracy for epoch 55:94.134\n",
            "Testing accuracy for epoch 55:89.32\n",
            "\n",
            "Epoch: 56\n",
            "Training accuracy for epoch 56:94.082\n",
            "Testing accuracy for epoch 56:90.06\n",
            "\n",
            "Epoch: 57\n",
            "Training accuracy for epoch 57:94.186\n",
            "Testing accuracy for epoch 57:90.24\n",
            "\n",
            "Epoch: 58\n",
            "Training accuracy for epoch 58:94.102\n",
            "Testing accuracy for epoch 58:89.51\n",
            "\n",
            "Epoch: 59\n",
            "Training accuracy for epoch 59:94.178\n",
            "Testing accuracy for epoch 59:89.69\n",
            "\n",
            "Epoch: 60\n",
            "Training accuracy for epoch 60:94.03200000000001\n",
            "Testing accuracy for epoch 60:90.25999999999999\n",
            "\n",
            "Epoch: 61\n",
            "Training accuracy for epoch 61:94.384\n",
            "Testing accuracy for epoch 61:89.89\n",
            "\n",
            "Epoch: 62\n",
            "Training accuracy for epoch 62:92.96\n",
            "Testing accuracy for epoch 62:89.02\n",
            "\n",
            "Epoch: 63\n",
            "Training accuracy for epoch 63:93.83399999999999\n",
            "Testing accuracy for epoch 63:90.51\n",
            "\n",
            "Epoch: 64\n",
            "Training accuracy for epoch 64:94.664\n",
            "Testing accuracy for epoch 64:90.48\n",
            "\n",
            "Epoch: 65\n",
            "Training accuracy for epoch 65:94.896\n",
            "Testing accuracy for epoch 65:90.53999999999999\n",
            "\n",
            "Epoch: 66\n",
            "Training accuracy for epoch 66:94.632\n",
            "Testing accuracy for epoch 66:90.81\n",
            "Saving..\n",
            "\n",
            "Epoch: 67\n",
            "Training accuracy for epoch 67:95.03200000000001\n",
            "Testing accuracy for epoch 67:90.96\n",
            "Saving..\n",
            "\n",
            "Epoch: 68\n",
            "Training accuracy for epoch 68:95.15599999999999\n",
            "Testing accuracy for epoch 68:89.03\n",
            "\n",
            "Epoch: 69\n",
            "Training accuracy for epoch 69:94.88799999999999\n",
            "Testing accuracy for epoch 69:90.44\n",
            "\n",
            "Epoch: 70\n",
            "Training accuracy for epoch 70:95.084\n",
            "Testing accuracy for epoch 70:90.25999999999999\n",
            "\n",
            "Epoch: 71\n",
            "Training accuracy for epoch 71:95.044\n",
            "Testing accuracy for epoch 71:89.66\n",
            "\n",
            "Epoch: 72\n",
            "Training accuracy for epoch 72:95.174\n",
            "Testing accuracy for epoch 72:90.49000000000001\n",
            "\n",
            "Epoch: 73\n",
            "Training accuracy for epoch 73:95.494\n",
            "Testing accuracy for epoch 73:91.21000000000001\n",
            "Saving..\n",
            "\n",
            "Epoch: 74\n",
            "Training accuracy for epoch 74:95.448\n",
            "Testing accuracy for epoch 74:90.69\n",
            "\n",
            "Epoch: 75\n",
            "Training accuracy for epoch 75:95.708\n",
            "Testing accuracy for epoch 75:90.47\n",
            "\n",
            "Epoch: 76\n",
            "Training accuracy for epoch 76:95.884\n",
            "Testing accuracy for epoch 76:90.75\n",
            "\n",
            "Epoch: 77\n",
            "Training accuracy for epoch 77:95.842\n",
            "Testing accuracy for epoch 77:91.09\n",
            "\n",
            "Epoch: 78\n",
            "Training accuracy for epoch 78:95.746\n",
            "Testing accuracy for epoch 78:90.66\n",
            "\n",
            "Epoch: 79\n",
            "Training accuracy for epoch 79:94.02199999999999\n",
            "Testing accuracy for epoch 79:91.3\n",
            "Saving..\n",
            "\n",
            "Epoch: 80\n",
            "Training accuracy for epoch 80:95.836\n",
            "Testing accuracy for epoch 80:90.82000000000001\n",
            "\n",
            "Epoch: 81\n",
            "Training accuracy for epoch 81:96.112\n",
            "Testing accuracy for epoch 81:90.67\n",
            "\n",
            "Epoch: 82\n",
            "Training accuracy for epoch 82:95.866\n",
            "Testing accuracy for epoch 82:91.22\n",
            "\n",
            "Epoch: 83\n",
            "Training accuracy for epoch 83:96.17\n",
            "Testing accuracy for epoch 83:91.09\n",
            "\n",
            "Epoch: 84\n",
            "Training accuracy for epoch 84:95.428\n",
            "Testing accuracy for epoch 84:91.45\n",
            "Saving..\n",
            "\n",
            "Epoch: 85\n",
            "Training accuracy for epoch 85:96.036\n",
            "Testing accuracy for epoch 85:91.75999999999999\n",
            "Saving..\n",
            "\n",
            "Epoch: 86\n",
            "Training accuracy for epoch 86:96.64\n",
            "Testing accuracy for epoch 86:91.16\n",
            "\n",
            "Epoch: 87\n",
            "Training accuracy for epoch 87:96.58\n",
            "Testing accuracy for epoch 87:91.29\n",
            "\n",
            "Epoch: 88\n",
            "Training accuracy for epoch 88:96.54599999999999\n",
            "Testing accuracy for epoch 88:91.19\n",
            "\n",
            "Epoch: 89\n",
            "Training accuracy for epoch 89:96.53\n",
            "Testing accuracy for epoch 89:90.99000000000001\n",
            "\n",
            "Epoch: 90\n",
            "Training accuracy for epoch 90:96.636\n",
            "Testing accuracy for epoch 90:91.25\n",
            "\n",
            "Epoch: 91\n",
            "Training accuracy for epoch 91:96.284\n",
            "Testing accuracy for epoch 91:90.86\n",
            "\n",
            "Epoch: 92\n",
            "Training accuracy for epoch 92:96.59\n",
            "Testing accuracy for epoch 92:91.14\n",
            "\n",
            "Epoch: 93\n",
            "Training accuracy for epoch 93:96.72\n",
            "Testing accuracy for epoch 93:90.74\n",
            "\n",
            "Epoch: 94\n",
            "Training accuracy for epoch 94:96.806\n",
            "Testing accuracy for epoch 94:91.0\n",
            "\n",
            "Epoch: 95\n",
            "Training accuracy for epoch 95:96.908\n",
            "Testing accuracy for epoch 95:91.29\n",
            "\n",
            "Epoch: 96\n",
            "Training accuracy for epoch 96:96.348\n",
            "Testing accuracy for epoch 96:91.91\n",
            "Saving..\n",
            "\n",
            "Epoch: 97\n",
            "Training accuracy for epoch 97:97.086\n",
            "Testing accuracy for epoch 97:91.53\n",
            "\n",
            "Epoch: 98\n",
            "Training accuracy for epoch 98:97.026\n",
            "Testing accuracy for epoch 98:91.62\n",
            "\n",
            "Epoch: 99\n",
            "Training accuracy for epoch 99:97.004\n",
            "Testing accuracy for epoch 99:90.98\n",
            "\n",
            "Epoch: 100\n",
            "Training accuracy for epoch 100:97.11999999999999\n",
            "Testing accuracy for epoch 100:90.71000000000001\n",
            "\n",
            "Epoch: 101\n",
            "Training accuracy for epoch 101:97.21\n",
            "Testing accuracy for epoch 101:91.33\n",
            "\n",
            "Epoch: 102\n",
            "Training accuracy for epoch 102:97.294\n",
            "Testing accuracy for epoch 102:91.4\n",
            "\n",
            "Epoch: 103\n",
            "Training accuracy for epoch 103:96.97\n",
            "Testing accuracy for epoch 103:91.62\n",
            "\n",
            "Epoch: 104\n",
            "Training accuracy for epoch 104:97.146\n",
            "Testing accuracy for epoch 104:91.01\n",
            "\n",
            "Epoch: 105\n",
            "Training accuracy for epoch 105:97.392\n",
            "Testing accuracy for epoch 105:91.18\n",
            "\n",
            "Epoch: 106\n",
            "Training accuracy for epoch 106:97.30799999999999\n",
            "Testing accuracy for epoch 106:89.84\n",
            "\n",
            "Epoch: 107\n",
            "Training accuracy for epoch 107:96.82\n",
            "Testing accuracy for epoch 107:91.57\n",
            "\n",
            "Epoch: 108\n",
            "Training accuracy for epoch 108:97.41199999999999\n",
            "Testing accuracy for epoch 108:91.97999999999999\n",
            "Saving..\n",
            "\n",
            "Epoch: 109\n",
            "Training accuracy for epoch 109:97.49600000000001\n",
            "Testing accuracy for epoch 109:91.06\n",
            "\n",
            "Epoch: 110\n",
            "Training accuracy for epoch 110:97.518\n",
            "Testing accuracy for epoch 110:91.32000000000001\n",
            "\n",
            "Epoch: 111\n",
            "Training accuracy for epoch 111:97.63199999999999\n",
            "Testing accuracy for epoch 111:91.69\n",
            "\n",
            "Epoch: 112\n",
            "Training accuracy for epoch 112:97.588\n",
            "Testing accuracy for epoch 112:91.13\n",
            "\n",
            "Epoch: 113\n",
            "Training accuracy for epoch 113:97.528\n",
            "Testing accuracy for epoch 113:91.12\n",
            "\n",
            "Epoch: 114\n",
            "Training accuracy for epoch 114:97.288\n",
            "Testing accuracy for epoch 114:91.57\n",
            "\n",
            "Epoch: 115\n",
            "Training accuracy for epoch 115:97.65599999999999\n",
            "Testing accuracy for epoch 115:91.31\n",
            "\n",
            "Epoch: 116\n",
            "Training accuracy for epoch 116:97.758\n",
            "Testing accuracy for epoch 116:91.59\n",
            "\n",
            "Epoch: 117\n",
            "Training accuracy for epoch 117:97.64\n",
            "Testing accuracy for epoch 117:91.47999999999999\n",
            "\n",
            "Epoch: 118\n",
            "Training accuracy for epoch 118:97.68599999999999\n",
            "Testing accuracy for epoch 118:91.81\n",
            "\n",
            "Epoch: 119\n",
            "Training accuracy for epoch 119:97.666\n",
            "Testing accuracy for epoch 119:91.53999999999999\n",
            "\n",
            "Epoch: 120\n",
            "Training accuracy for epoch 120:97.83\n",
            "Testing accuracy for epoch 120:91.09\n",
            "\n",
            "Epoch: 121\n",
            "Training accuracy for epoch 121:97.652\n",
            "Testing accuracy for epoch 121:91.55\n",
            "\n",
            "Epoch: 122\n",
            "Training accuracy for epoch 122:97.774\n",
            "Testing accuracy for epoch 122:91.58\n",
            "\n",
            "Epoch: 123\n",
            "Training accuracy for epoch 123:97.81\n",
            "Testing accuracy for epoch 123:91.62\n",
            "\n",
            "Epoch: 124\n",
            "Training accuracy for epoch 124:96.81\n",
            "Testing accuracy for epoch 124:91.57\n",
            "\n",
            "Epoch: 125\n",
            "Training accuracy for epoch 125:97.83800000000001\n",
            "Testing accuracy for epoch 125:91.92\n",
            "\n",
            "Epoch: 126\n",
            "Training accuracy for epoch 126:97.978\n",
            "Testing accuracy for epoch 126:91.75999999999999\n",
            "\n",
            "Epoch: 127\n",
            "Training accuracy for epoch 127:98.29\n",
            "Testing accuracy for epoch 127:91.57\n",
            "\n",
            "Epoch: 128\n",
            "Training accuracy for epoch 128:97.978\n",
            "Testing accuracy for epoch 128:92.19000000000001\n",
            "Saving..\n",
            "\n",
            "Epoch: 129\n",
            "Training accuracy for epoch 129:97.96000000000001\n",
            "Testing accuracy for epoch 129:91.35\n",
            "\n",
            "Epoch: 130\n",
            "Training accuracy for epoch 130:98.102\n",
            "Testing accuracy for epoch 130:91.21000000000001\n",
            "\n",
            "Epoch: 131\n",
            "Training accuracy for epoch 131:97.96000000000001\n",
            "Testing accuracy for epoch 131:91.71000000000001\n",
            "\n",
            "Epoch: 132\n",
            "Training accuracy for epoch 132:97.91\n",
            "Testing accuracy for epoch 132:90.85\n",
            "\n",
            "Epoch: 133\n",
            "Training accuracy for epoch 133:98.05199999999999\n",
            "Testing accuracy for epoch 133:92.16\n",
            "\n",
            "Epoch: 134\n",
            "Training accuracy for epoch 134:97.422\n",
            "Testing accuracy for epoch 134:92.12\n",
            "\n",
            "Epoch: 135\n",
            "Training accuracy for epoch 135:98.10799999999999\n",
            "Testing accuracy for epoch 135:91.60000000000001\n",
            "\n",
            "Epoch: 136\n",
            "Training accuracy for epoch 136:98.212\n",
            "Testing accuracy for epoch 136:91.61\n",
            "\n",
            "Epoch: 137\n",
            "Training accuracy for epoch 137:98.184\n",
            "Testing accuracy for epoch 137:91.78\n",
            "\n",
            "Epoch: 138\n",
            "Training accuracy for epoch 138:97.98400000000001\n",
            "Testing accuracy for epoch 138:91.33\n",
            "\n",
            "Epoch: 139\n",
            "Training accuracy for epoch 139:98.22\n",
            "Testing accuracy for epoch 139:91.29\n",
            "\n",
            "Epoch: 140\n",
            "Training accuracy for epoch 140:98.18\n",
            "Testing accuracy for epoch 140:90.79\n",
            "\n",
            "Epoch: 141\n",
            "Training accuracy for epoch 141:98.08200000000001\n",
            "Testing accuracy for epoch 141:91.58\n",
            "\n",
            "Epoch: 142\n",
            "Training accuracy for epoch 142:97.978\n",
            "Testing accuracy for epoch 142:92.07\n",
            "\n",
            "Epoch: 143\n",
            "Training accuracy for epoch 143:98.03399999999999\n",
            "Testing accuracy for epoch 143:90.5\n",
            "\n",
            "Epoch: 144\n",
            "Training accuracy for epoch 144:98.15\n",
            "Testing accuracy for epoch 144:91.60000000000001\n",
            "\n",
            "Epoch: 145\n",
            "Training accuracy for epoch 145:97.604\n",
            "Testing accuracy for epoch 145:91.38\n",
            "\n",
            "Epoch: 146\n",
            "Training accuracy for epoch 146:98.05199999999999\n",
            "Testing accuracy for epoch 146:92.22\n",
            "Saving..\n",
            "\n",
            "Epoch: 147\n",
            "Training accuracy for epoch 147:98.458\n",
            "Testing accuracy for epoch 147:91.41\n",
            "\n",
            "Epoch: 148\n",
            "Training accuracy for epoch 148:98.396\n",
            "Testing accuracy for epoch 148:91.91\n",
            "\n",
            "Epoch: 149\n",
            "Training accuracy for epoch 149:98.404\n",
            "Testing accuracy for epoch 149:92.41\n",
            "Saving..\n",
            "\n",
            "Epoch: 150\n",
            "Training accuracy for epoch 150:98.556\n",
            "Testing accuracy for epoch 150:92.36\n",
            "\n",
            "Epoch: 151\n",
            "Training accuracy for epoch 151:98.038\n",
            "Testing accuracy for epoch 151:91.33\n",
            "\n",
            "Epoch: 152\n",
            "Training accuracy for epoch 152:98.348\n",
            "Testing accuracy for epoch 152:91.86\n",
            "\n",
            "Epoch: 153\n",
            "Training accuracy for epoch 153:98.38\n",
            "Testing accuracy for epoch 153:91.89\n",
            "\n",
            "Epoch: 154\n",
            "Training accuracy for epoch 154:98.392\n",
            "Testing accuracy for epoch 154:91.59\n",
            "\n",
            "Epoch: 155\n",
            "Training accuracy for epoch 155:98.392\n",
            "Testing accuracy for epoch 155:91.85\n",
            "\n",
            "Epoch: 156\n",
            "Training accuracy for epoch 156:98.414\n",
            "Testing accuracy for epoch 156:92.13\n",
            "\n",
            "Epoch: 157\n",
            "Training accuracy for epoch 157:98.386\n",
            "Testing accuracy for epoch 157:91.74\n",
            "\n",
            "Epoch: 158\n",
            "Training accuracy for epoch 158:98.218\n",
            "Testing accuracy for epoch 158:91.25999999999999\n",
            "\n",
            "Epoch: 159\n",
            "Training accuracy for epoch 159:98.374\n",
            "Testing accuracy for epoch 159:91.93\n",
            "\n",
            "Epoch: 160\n",
            "Training accuracy for epoch 160:98.49799999999999\n",
            "Testing accuracy for epoch 160:92.17999999999999\n",
            "\n",
            "Epoch: 161\n",
            "Training accuracy for epoch 161:98.512\n",
            "Testing accuracy for epoch 161:91.96\n",
            "\n",
            "Epoch: 162\n",
            "Training accuracy for epoch 162:98.354\n",
            "Testing accuracy for epoch 162:92.08\n",
            "\n",
            "Epoch: 163\n",
            "Training accuracy for epoch 163:98.538\n",
            "Testing accuracy for epoch 163:92.09\n",
            "\n",
            "Epoch: 164\n",
            "Training accuracy for epoch 164:98.272\n",
            "Testing accuracy for epoch 164:91.62\n",
            "\n",
            "Epoch: 165\n",
            "Training accuracy for epoch 165:98.462\n",
            "Testing accuracy for epoch 165:92.13\n",
            "\n",
            "Epoch: 166\n",
            "Training accuracy for epoch 166:98.546\n",
            "Testing accuracy for epoch 166:91.63\n",
            "\n",
            "Epoch: 167\n",
            "Training accuracy for epoch 167:98.55199999999999\n",
            "Testing accuracy for epoch 167:91.99000000000001\n",
            "\n",
            "Epoch: 168\n",
            "Training accuracy for epoch 168:98.408\n",
            "Testing accuracy for epoch 168:92.11\n",
            "\n",
            "Epoch: 169\n",
            "Training accuracy for epoch 169:95.904\n",
            "Testing accuracy for epoch 169:90.3\n",
            "\n",
            "Epoch: 170\n",
            "Training accuracy for epoch 170:97.576\n",
            "Testing accuracy for epoch 170:91.60000000000001\n",
            "\n",
            "Epoch: 171\n",
            "Training accuracy for epoch 171:98.444\n",
            "Testing accuracy for epoch 171:91.9\n",
            "\n",
            "Epoch: 172\n",
            "Training accuracy for epoch 172:98.648\n",
            "Testing accuracy for epoch 172:91.97999999999999\n",
            "\n",
            "Epoch: 173\n",
            "Training accuracy for epoch 173:98.782\n",
            "Testing accuracy for epoch 173:92.24\n",
            "\n",
            "Epoch: 174\n",
            "Training accuracy for epoch 174:98.762\n",
            "Testing accuracy for epoch 174:91.86999999999999\n",
            "\n",
            "Epoch: 175\n",
            "Training accuracy for epoch 175:98.828\n",
            "Testing accuracy for epoch 175:92.21000000000001\n",
            "\n",
            "Epoch: 176\n",
            "Training accuracy for epoch 176:98.66\n",
            "Testing accuracy for epoch 176:91.53999999999999\n",
            "\n",
            "Epoch: 177\n",
            "Training accuracy for epoch 177:98.86\n",
            "Testing accuracy for epoch 177:91.91\n",
            "\n",
            "Epoch: 178\n",
            "Training accuracy for epoch 178:98.656\n",
            "Testing accuracy for epoch 178:92.46\n",
            "Saving..\n",
            "\n",
            "Epoch: 179\n",
            "Training accuracy for epoch 179:98.68400000000001\n",
            "Testing accuracy for epoch 179:91.36999999999999\n",
            "\n",
            "Epoch: 180\n",
            "Training accuracy for epoch 180:98.584\n",
            "Testing accuracy for epoch 180:92.15\n",
            "\n",
            "Epoch: 181\n",
            "Training accuracy for epoch 181:98.752\n",
            "Testing accuracy for epoch 181:92.15\n",
            "\n",
            "Epoch: 182\n",
            "Training accuracy for epoch 182:98.662\n",
            "Testing accuracy for epoch 182:92.34\n",
            "\n",
            "Epoch: 183\n",
            "Training accuracy for epoch 183:98.734\n",
            "Testing accuracy for epoch 183:91.85\n",
            "\n",
            "Epoch: 184\n",
            "Training accuracy for epoch 184:98.676\n",
            "Testing accuracy for epoch 184:91.42\n",
            "\n",
            "Epoch: 185\n",
            "Training accuracy for epoch 185:98.61999999999999\n",
            "Testing accuracy for epoch 185:91.67\n",
            "\n",
            "Epoch: 186\n",
            "Training accuracy for epoch 186:98.574\n",
            "Testing accuracy for epoch 186:91.52\n",
            "\n",
            "Epoch: 187\n",
            "Training accuracy for epoch 187:98.784\n",
            "Testing accuracy for epoch 187:91.75999999999999\n",
            "\n",
            "Epoch: 188\n",
            "Training accuracy for epoch 188:98.6\n",
            "Testing accuracy for epoch 188:91.95\n",
            "\n",
            "Epoch: 189\n",
            "Training accuracy for epoch 189:98.576\n",
            "Testing accuracy for epoch 189:92.31\n",
            "\n",
            "Epoch: 190\n",
            "Training accuracy for epoch 190:98.708\n",
            "Testing accuracy for epoch 190:92.03\n",
            "\n",
            "Epoch: 191\n",
            "Training accuracy for epoch 191:98.688\n",
            "Testing accuracy for epoch 191:91.89\n",
            "\n",
            "Epoch: 192\n",
            "Training accuracy for epoch 192:98.418\n",
            "Testing accuracy for epoch 192:91.96\n",
            "\n",
            "Epoch: 193\n",
            "Training accuracy for epoch 193:98.792\n",
            "Testing accuracy for epoch 193:92.35\n",
            "\n",
            "Epoch: 194\n",
            "Training accuracy for epoch 194:98.668\n",
            "Testing accuracy for epoch 194:92.16\n",
            "\n",
            "Epoch: 195\n",
            "Training accuracy for epoch 195:98.664\n",
            "Testing accuracy for epoch 195:92.0\n",
            "\n",
            "Epoch: 196\n",
            "Training accuracy for epoch 196:98.706\n",
            "Testing accuracy for epoch 196:91.64999999999999\n",
            "\n",
            "Epoch: 197\n",
            "Training accuracy for epoch 197:98.642\n",
            "Testing accuracy for epoch 197:92.39\n",
            "\n",
            "Epoch: 198\n",
            "Training accuracy for epoch 198:98.816\n",
            "Testing accuracy for epoch 198:92.2\n",
            "\n",
            "Epoch: 199\n",
            "Training accuracy for epoch 199:98.854\n",
            "Testing accuracy for epoch 199:92.17999999999999\n",
            "92.46\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}